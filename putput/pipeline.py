import logging
from functools import reduce
from pathlib import Path
from typing import Any
from typing import Callable
from typing import Dict  # pylint: disable=unused-import
from typing import Iterable
from typing import Mapping
from typing import Optional
from typing import Sequence
from typing import Tuple
from typing import Type
from typing import TypeVar
from typing import Union
from typing import overload

import yaml

from putput.combiner import combine
from putput.expander import expand
from putput.expander import expand_utterance_patterns_ranges_and_groups
from putput.expander import get_base_item_map
from putput.joiner import ComboOptions
from putput.logger import get_logger
from putput.presets.factory import get_preset
from putput.validator import validate_pattern_def

try:
    get_ipython() # type: ignore
    from tqdm import tqdm_notebook as tqdm # pragma: no cover
except NameError:
    from tqdm import tqdm

_E_H_MAP = Mapping[Any, Sequence[Callable[[Sequence[Sequence[str]], Sequence[str], Sequence[Tuple[str, int]]],
                                          Tuple[Sequence[Sequence[str]], Sequence[str], Sequence[Tuple[str, int]]]]]]
_C_H_MAP = Mapping[Any, Sequence[Callable[[Any, Any, Any], Tuple[Any, Any, Any]]]]
_T_UP_KEY = TypeVar('_T_UP_KEY',
                    _C_H_MAP,
                    _E_H_MAP,
                    Mapping[Any, ComboOptions])
T_PIPELINE = TypeVar('T_PIPELINE', bound='Pipeline')

class Pipeline:
    """Transforms a pattern definition into labeled data.

    To perform this transformation, initialize 'Pipeline' and
    call 'flow'.

    There are two ways to initialize 'Pipeline': by passing
    in desired arguments or through the use of a 'preset' in
    the method 'from_preset'. 'Presets' instantiate the 'Pipeline'
    with arguments that cover common use cases. As these arguments
    become attributes that the user can modify, using a 'preset' does
    not give up customizability.

    Once 'Pipeline' has been initialized, calling the method 'flow'
    will cause labeled data to flow through 'Pipeline' to the user.

    There are two stages in 'flow'. The first stage, 'expansion', expands
    the pattern definition file into an 'utterance_combo', 'tokens', and 'groups'
    for each utterance pattern. At the end of the first stage,
    if hooks in 'expansion_hooks_map' are specified for the
    current utterance pattern, they are applied in order where the output
    of a previous hook becomes the input to the next hook.

    The second stage, 'combination', yields a sequence of
    'utterance', 'handled_tokens', and 'handled_groups'. This stage
    applies handlers from 'token_handler_map' and 'group_handler_map' and
    is subject to constraints specified in 'combo_options_map'.
    At the end of the second stage, if hooks in 'combo_hooks_map' are
    specified for the current 'utterance_pattern', they are applied
    in order where the output of a previous hook becomes the input
    to the next hook.

    Finally, if a 'final_hook' is specified, it will be applied to the
    output of the combination stage, and 'flow' will yield its result.
    If a 'final_hook' is not specified, 'flow' will yield the result
    of the combination stage, a sequence of 'utterance', 'handled_tokens',
    and 'handled_groups'.

    Attributes:
        pattern_def: A dictionary representation of the pattern definition.

        dynamic_token_patterns_map: The dynamic counterpart to the static section in the
            pattern definition. This mapping between token and token patterns is useful in
            scenarios where tokens and token patterns cannot be known before runtime.

        token_handler_map: A mapping between a token and a function with args
            (token, phrase generated by token) that returns a handled token. If 'DEFAULT'
            is specified as the token, the handler will apply to all tokens not otherwise
            specified in the mapping.

        group_handler_map: A mapping between a group name and a function with args
            (group name, handled tokens) that returns a handled group. If 'DEFAULT' is
            specified as the group name, the handler will apply to all groups not otherwise
            specified in the mapping.

        expansion_hooks_map: A mapping between an utterance pattern and hooks to apply after
            the expansion phase. If 'DEFAULT' is specified as the utterance pattern, the hooks
            will apply to all utterance patterns not otherwise specified in the mapping. During,
            'flow', hooks are applied in order where the output of the previous hook becomes
            the input to the next hook.

        combo_hooks_map: A mapping between an utterance pattern and hooks to apply after
            the combination phase. If 'DEFAULT' is specified as the utterance pattern, the hooks
            will apply to all utterance patterns not otherwise specified in the mapping. During,
            'flow', hooks are applied in order where the output of the previous hook becomes
            the input to the next hook.

        combo_options: A mapping between an utterance pattern and ComboOptions to apply during
            the combination phase. If 'DEFAULT' is specified as the utterance pattern, the options
            will apply to all utterance patterns not otherwise specified in the mapping.

        final_hook: A function with args (utterance, handled tokens, handled groups) that returns
            a value that will be returned by the flow method. If combo_hooks_map is specified,
            the input args to final_hook will be the return values of the last hook in combo_hooks_map.

    Examples:
        Default behavior

        >>> pattern_def_path = Path(__file__).parent.parent / 'tests' / 'doc' / 'example_pattern_definition.yml'
        >>> dynamic_token_patterns_map = {'ITEM': ((('fries',),),)}
        >>> p = Pipeline(pattern_def_path, dynamic_token_patterns_map=dynamic_token_patterns_map)
        >>> generator = p.flow(disable_progress_bar=True)
        >>> for utterance, tokens, groups in generator:
        ...     print(utterance)
        ...     print(tokens)
        ...     print(groups)
        can she get fries can she get fries and fries
        ('[ADD(can she get)]', '[ITEM(fries)]', '[ADD(can she get)]', '[ITEM(fries)]', '[CONJUNCTION(and)]',
        '[ITEM(fries)]')
        ('{ADD_ITEM([ADD(can she get)] [ITEM(fries)])}', '{ADD_ITEM([ADD(can she get)] [ITEM(fries)])}',
        '{None([CONJUNCTION(and)])}', '{None([ITEM(fries)])}')
        can she get fries may she get fries and fries
        ('[ADD(can she get)]', '[ITEM(fries)]', '[ADD(may she get)]', '[ITEM(fries)]', '[CONJUNCTION(and)]',
        '[ITEM(fries)]')
        ('{ADD_ITEM([ADD(can she get)] [ITEM(fries)])}', '{ADD_ITEM([ADD(may she get)] [ITEM(fries)])}',
        '{None([CONJUNCTION(and)])}', '{None([ITEM(fries)])}')
        may she get fries can she get fries and fries
        ('[ADD(may she get)]', '[ITEM(fries)]', '[ADD(can she get)]', '[ITEM(fries)]', '[CONJUNCTION(and)]',
        '[ITEM(fries)]')
        ('{ADD_ITEM([ADD(may she get)] [ITEM(fries)])}', '{ADD_ITEM([ADD(can she get)] [ITEM(fries)])}',
        '{None([CONJUNCTION(and)])}', '{None([ITEM(fries)])}')
        may she get fries may she get fries and fries
        ('[ADD(may she get)]', '[ITEM(fries)]', '[ADD(may she get)]', '[ITEM(fries)]', '[CONJUNCTION(and)]',
        '[ITEM(fries)]')
        ('{ADD_ITEM([ADD(may she get)] [ITEM(fries)])}', '{ADD_ITEM([ADD(may she get)] [ITEM(fries)])}',
        '{None([CONJUNCTION(and)])}', '{None([ITEM(fries)])}')

        With arguments

        >>> import json
        >>> import random
        >>> def _just_tokens(token: str, _: str) -> str:
        ...     return '[{token}]'.format(token=token)
        >>> def _just_groups(group_name: str, _: Sequence[str]) -> str:
        ...     return '[{group_name}]'.format(group_name=group_name)
        >>> def _add_random_words(utterance: str,
        ...                       handled_tokens: Sequence[str],
        ...                       handled_groups: Sequence[str]
        ...                       ) -> Tuple[str, Sequence[str], Sequence[str]]:
        ...     utterances = utterance.split()
        ...     random_words = ['hmmmm', 'uh', 'um', 'please']
        ...     insert_index = random.randint(0, len(utterances))
        ...     random_word = random.choice(random_words)
        ...     utterances.insert(insert_index, random_word)
        ...     utterance = ' '.join(utterances)
        ...     return utterance, handled_tokens, handled_groups
        >>> def jsonify(utterance: str,
        ...             handled_tokens: Sequence[str],
        ...             handled_groups: Sequence[str]
        ...             ) -> str:
        ...     return json.dumps(dict(utterance=utterance,
        ...                            handled_tokens=handled_tokens,
        ...                            handled_groups=handled_groups),
        ...                       sort_keys=True)
        >>> def _sample_utterance_combo(utterance_combo: Sequence[Sequence[str]],
        ...                             tokens: Sequence[str],
        ...                             groups: Sequence[Tuple[str, int]]
        ...                             ) -> Tuple[Sequence[Sequence[str]], Sequence[str], Sequence[Tuple[str, int]]]:
        ...        random.seed(0)
        ...        TOKEN_INDEX = tokens.index('ADD')
        ...        utterance_combo_list = list(utterance_combo)
        ...        sampled_combos = tuple(random.sample(utterance_combo_list.pop(TOKEN_INDEX), 1))
        ...        utterance_combo_list.insert(TOKEN_INDEX, sampled_combos)
        ...        utterance_combo = tuple(utterance_combo_list)
        ...        return utterance_combo, tokens, groups
        >>> token_handler_map = {'ITEM': _just_tokens}
        >>> group_handler_map = {'ADD_ITEM': _just_groups}
        >>> expansion_hooks_map = {('ADD_ITEM', '2', 'CONJUNCTION', 'ITEM'): (_sample_utterance_combo,)}
        >>> combo_hooks_map = {('ADD_ITEM', '2', 'CONJUNCTION', 'ITEM'): (_add_random_words, _add_random_words)}
        >>> combo_options_map = {'DEFAULT': ComboOptions(max_sample_size=2, with_replacement=False, seed=0)}
        >>> p = Pipeline(pattern_def_path,
        ...              dynamic_token_patterns_map=dynamic_token_patterns_map,
        ...              token_handler_map=token_handler_map,
        ...              group_handler_map=group_handler_map,
        ...              expansion_hooks_map=expansion_hooks_map,
        ...              combo_hooks_map=combo_hooks_map,
        ...              combo_options_map=combo_options_map,
        ...              final_hook=jsonify)
        >>> for json_result in p.flow(disable_progress_bar=True):
        ...     print(json_result)
        {"handled_groups": ["[ADD_ITEM]", "[ADD_ITEM]", "{None([CONJUNCTION(and)])}", "{None([ITEM])}"],
         "handled_tokens": ["[ADD(may she get)]", "[ITEM]", "[ADD(may she get)]", "[ITEM]", "[CONJUNCTION(and)]",
                            "[ITEM]"],
         "utterance": "um may she get fries may she get please fries and fries"}
        {"handled_groups": ["[ADD_ITEM]", "[ADD_ITEM]", "{None([CONJUNCTION(and)])}", "{None([ITEM])}"],
         "handled_tokens": ["[ADD(may she get)]", "[ITEM]", "[ADD(can she get)]", "[ITEM]", "[CONJUNCTION(and)]",
                            "[ITEM]"],
         "utterance": "may she get fries can she um um get fries and fries"}

        With a preset

        >>> dynamic_token_patterns_map = {'ITEM': ((('fries',),),)}
        >>> p = Pipeline.from_preset('IOB2',
        ...                          pattern_def_path,
        ...                          dynamic_token_patterns_map=dynamic_token_patterns_map)
        >>> generator = p.flow(disable_progress_bar=True)
        >>> for utterance, tokens, groups in generator:
        ...     print(utterance)
        ...     print(tokens)
        ...     print(groups)
        ...     break
        can she get fries can she get fries and fries
        ('B-ADD I-ADD I-ADD', 'B-ITEM', 'B-ADD I-ADD I-ADD', 'B-ITEM', 'B-CONJUNCTION', 'B-ITEM')
        ('B-ADD_ITEM I-ADD_ITEM I-ADD_ITEM I-ADD_ITEM', 'B-ADD_ITEM I-ADD_ITEM I-ADD_ITEM I-ADD_ITEM', 'B-None',
         'B-None')
    """

    # pylint: disable=too-many-instance-attributes
    def __init__(self,
                 pattern_def_path: Path,
                 *,
                 dynamic_token_patterns_map: Optional[Mapping[str, Sequence[Sequence[Sequence[str]]]]] = None,
                 token_handler_map: Optional[Mapping[str, Callable[[str, str], str]]] = None,
                 group_handler_map: Optional[Mapping[str, Callable[[str, Sequence[str]], str]]] = None,
                 expansion_hooks_map: Optional[_E_H_MAP] = None,
                 combo_hooks_map: Optional[_C_H_MAP] = None,
                 combo_options_map: Optional[Mapping[Any, ComboOptions]] = None,
                 final_hook: Optional[Callable[[Any, Any, Any], Any]] = None,
                 log_level: int = logging.WARNING
                 ) -> None:
        """Instantiates 'Pipeline'.

        Validates the pattern definition, expands utterance patterns used as keys in maps,
        and sets public attributes.

        Args:
            pattern_def_path: Path to the pattern definition file.

            dynamic_token_patterns_map: The dynamic counterpart to the static section in the
                pattern definition. This mapping between token and token patterns is useful in
                scenarios where tokens and token patterns cannot be known before runtime.

            token_handler_map: A mapping between a token and a function with args
                (token, phrase generated by token) that returns a handled token. If 'DEFAULT'
                is specified as the token, the handler will apply to all tokens not otherwise
                specified in the mapping.

            group_handler_map: A mapping between a group name and a function with args
                (group name, handled tokens) that returns a handled group. If 'DEFAULT' is
                specified as the group name, the handler will apply to all groups not otherwise
                specified in the mapping.

            expansion_hooks_map: A mapping between an utterance pattern and hooks to apply after
                the expansion phase. If 'DEFAULT' is specified as the utterance pattern, the hooks
                will apply to all utterance patterns not otherwise specified in the mapping. During,
                'flow', hooks are applied in order where the output of the previous hook becomes
                the input to the next hook.

            combo_hooks_map: A mapping between an utterance pattern and hooks to apply after
                the combination phase. If 'DEFAULT' is specified as the utterance pattern, the hooks
                will apply to all utterance patterns not otherwise specified in the mapping. During,
                'flow', hooks are applied in order where the output of the previous hook becomes
                the input to the next hook.

            combo_options: A mapping between an utterance pattern and ComboOptions to apply during
                the combination phase. If 'DEFAULT' is specified as the utterance pattern, the options
                will apply to all utterance patterns not otherwise specified in the mapping.

            final_hook: A function with args (utterance, handled tokens, handled groups) that returns
                a value that will be returned by the flow method. If combo_hooks_map is specified,
                the input args to final_hook will be the return values of the last hook in combo_hooks_map.

            log_level: Minimum logging level. Messages with this level or higher will be shown.

        Raises:
            PatternDefinitionValidationError: If the pattern definition file is invalid.
            ScannerError: If the pattern definition file is not YAML.
            # TODO: find the rest of the yaml errors or wrap in common error
            # TODO: attributes should be properties that expand when new keys are set
        """
        self.pattern_def = _load_pattern_def(pattern_def_path)
        validate_pattern_def(self.pattern_def)
        maps_with_utterance_pattern_as_key = (i for i in (expansion_hooks_map, combo_hooks_map, combo_options_map) if i)
        self._validate_key_types_for_maps_with_utterance_pattern_as_key(maps_with_utterance_pattern_as_key)

        self.dynamic_token_patterns_map = dynamic_token_patterns_map
        self.token_handler_map = token_handler_map
        self.group_handler_map = group_handler_map

        groups_map = get_base_item_map(self.pattern_def, 'groups')
        if expansion_hooks_map:
            self.expansion_hooks_map = self._expand_map_with_utterance_pattern_as_key(
                expansion_hooks_map, groups_map) # type: Optional[_E_H_MAP]
        else:
            self.expansion_hooks_map = None

        if combo_hooks_map:
            self.combo_hooks_map = self._expand_map_with_utterance_pattern_as_key(
                combo_hooks_map, groups_map)  # type: Optional[_C_H_MAP]
        else:
            self.combo_hooks_map = None

        if combo_options_map:
            self.combo_options_map = self._expand_map_with_utterance_pattern_as_key(
                combo_options_map, groups_map) # type: Optional[Mapping[Any, ComboOptions]]
        else:
            self.combo_options_map = None

        self.final_hook = final_hook
        self._logger = get_logger(__name__, log_level)

    @classmethod
    def from_preset(cls: Type[T_PIPELINE],
                    preset: Union[str, Callable],
                    *args: Any,
                    **kwargs: Any) -> T_PIPELINE:
        """Instantiates 'Pipeline' from a preset configuration.

        There are two ways to use 'from_preset'. The simplest way is to use the
        preset's name. However, presets may have optional arguments that allow
        for more control. In that case, use a call to the preset's method, 'preset',
        with the desired arguments.

        Args:
            preset: A str that is the preset's name, or a Callable that is the
                result of calling the preset's 'preset' function. The Callable
                form allows more control over the preset's behavior.

            args: See __init__ docstring.

            kwargs: See __init__ docstring.

        Returns:
            An instance of Pipeline.

        Examples:
            Preset str

            >>> from pathlib import Path
            >>> from putput.pipeline import Pipeline
            >>> pattern_def_path = Path(__file__).parent.parent / 'tests' / 'doc' / 'example_pattern_definition.yml'
            >>> dynamic_token_patterns_map = {'ITEM': ((('fries',),),)}
            >>> p = Pipeline.from_preset('IOB2',
            ...                          pattern_def_path,
            ...                          dynamic_token_patterns_map=dynamic_token_patterns_map)
            >>> generator = p.flow(disable_progress_bar=True)
            >>> for utterance, tokens, groups in generator:
            ...     print(utterance)
            ...     print(tokens)
            ...     print(groups)
            ...     break
            can she get fries can she get fries and fries
            ('B-ADD I-ADD I-ADD', 'B-ITEM', 'B-ADD I-ADD I-ADD', 'B-ITEM', 'B-CONJUNCTION', 'B-ITEM')
            ('B-ADD_ITEM I-ADD_ITEM I-ADD_ITEM I-ADD_ITEM', 'B-ADD_ITEM I-ADD_ITEM I-ADD_ITEM I-ADD_ITEM',
            'B-None', 'B-None')

            Preset function with arguments

            >>> from putput.presets import iob2
            >>> p = Pipeline.from_preset(iob2.preset(tokens_to_include=('ITEM',), groups_to_include=('ADD_ITEM',)),
            ...                          pattern_def_path,
            ...                          dynamic_token_patterns_map=dynamic_token_patterns_map)
            >>> generator = p.flow(disable_progress_bar=True)
            >>> for utterance, tokens, groups in generator:
            ...     print(utterance)
            ...     print(tokens)
            ...     print(groups)
            ...     break
            can she get fries can she get fries and fries
            ('O O O', 'B-ITEM', 'O O O', 'B-ITEM', 'O', 'B-ITEM')
            ('B-ADD_ITEM I-ADD_ITEM I-ADD_ITEM I-ADD_ITEM', 'B-ADD_ITEM I-ADD_ITEM I-ADD_ITEM I-ADD_ITEM', 'O', 'O')
        """
        if isinstance(preset, str):
            preset = get_preset(preset)
        init_kwargs = preset()
        init_kwargs.update(kwargs)
        return cls(*args, **init_kwargs)

    @property
    def logger(self) -> logging.Logger:
        """Logger configured for Pipeline."""
        return self._logger

    def flow(self, *, disable_progress_bar: bool = False) -> Iterable:
        """Generates labeled data one utterance at a time.

        Args:
            disable_progress_bar: Option to display progress of expansion
                and combination stages as the Iterable is consumed.

        Yields:
            Labeled data.

        Examples:
            >>> from pathlib import Path
            >>> from putput.pipeline import Pipeline
            >>> pattern_def_path = Path(__file__).parent.parent / 'tests' / 'doc' / 'example_pattern_definition.yml'
            >>> dynamic_token_patterns_map = {'ITEM': ((('fries',),),)}
            >>> p = Pipeline(pattern_def_path, dynamic_token_patterns_map=dynamic_token_patterns_map)
            >>> generator = p.flow(disable_progress_bar=True)
            >>> for utterance, tokens, groups in generator:
            ...     print(utterance)
            ...     print(tokens)
            ...     print(groups)
            ...     break
            can she get fries can she get fries and fries
            ('[ADD(can she get)]', '[ITEM(fries)]', '[ADD(can she get)]', '[ITEM(fries)]',
            '[CONJUNCTION(and)]', '[ITEM(fries)]')
            ('{ADD_ITEM([ADD(can she get)] [ITEM(fries)])}', '{ADD_ITEM([ADD(can she get)] [ITEM(fries)])}',
            '{None([CONJUNCTION(and)])}', '{None([ITEM(fries)])}')
        """
        for utterance_combo, tokens, groups in self._expand(disable_progress_bar=disable_progress_bar):
            for utterance, handled_tokens, handled_groups in self._combine(utterance_combo,
                                                                           tokens,
                                                                           groups,
                                                                           disable_progress_bar=disable_progress_bar):
                if self.final_hook:
                    final_result = self.final_hook(utterance, handled_tokens, handled_groups)
                    if final_result:
                        yield final_result
                else:
                    yield utterance, handled_tokens, handled_groups

    def _combine(self,
                 utterance_combo: Sequence[Sequence[str]],
                 tokens: Sequence[str],
                 groups: Sequence[Tuple[str, int]],
                 *,
                 disable_progress_bar: bool = False
                 ) -> Iterable[Tuple[str, Sequence[str], Sequence[str]]]:
        combo_options = self._get_combo_options(tokens, self.combo_options_map) if self.combo_options_map else None

        sample_size, combo_gen = combine(utterance_combo,
                                         tokens,
                                         token_handler_map=self.token_handler_map,
                                         combo_options=combo_options)
        with tqdm(combo_gen,
                  desc='Combination...',
                  total=sample_size,
                  disable=disable_progress_bar,
                  leave=False,
                  miniters=1) as pbar:
            for utterance, handled_tokens in pbar:
                handled_groups = self._compute_handled_groups(groups, handled_tokens)
                if self.combo_hooks_map:
                    utterance, handled_tokens, handled_groups = self._execute_joining_hooks(tokens,
                                                                                            (utterance,
                                                                                             handled_tokens,
                                                                                             handled_groups),
                                                                                            self.combo_hooks_map)
                yield utterance, handled_tokens, handled_groups

    def _expand(self,
                *,
                disable_progress_bar: bool = False
                ) -> Iterable[Tuple[Sequence[Sequence[str]], Sequence[str], Sequence[Tuple[str, int]]]]:
        ilen, exp_gen = expand(self.pattern_def, dynamic_token_patterns_map=self.dynamic_token_patterns_map)
        with tqdm(exp_gen, desc='Expansion...', total=ilen, disable=disable_progress_bar, miniters=1) as expansion_tqdm:
            for utterance_combo, tokens, groups in expansion_tqdm:
                log_msg = '{}'.format(', '.join(tokens))
                self._logger.info(log_msg)
                if self.expansion_hooks_map:
                    utterance_combo, tokens, groups = self._execute_joining_hooks(tokens,
                                                                                  (utterance_combo, tokens, groups),
                                                                                  self.expansion_hooks_map)
                yield utterance_combo, tokens, groups

    def _get_combo_options(self,
                           tokens: Sequence[str],
                           combo_options_map: Mapping[Any, ComboOptions]
                           ) -> Optional[ComboOptions]:
        # pylint: disable=no-self-use
        options_map = {} # type: Dict[Union[str, Tuple[str, ...]], ComboOptions]
        options_map.update(combo_options_map)
        key = tuple(tokens)
        return options_map.get(key) or options_map.get('DEFAULT')

    @overload
    def _execute_joining_hooks(self,
                               tokens: Sequence[str],
                               args: Tuple[Sequence[Sequence[str]], Sequence[str], Sequence[Tuple[str, int]]],
                               hooks_map: _E_H_MAP,
                               ) -> Tuple[Sequence[Sequence[str]], Sequence[str], Sequence[Tuple[str, int]]]:
        # pylint: disable=no-self-use
        # pylint: disable=unused-argument
        pass # pragma: no cover

    @overload
    def _execute_joining_hooks(self,
                               tokens: Sequence[str],
                               args: Tuple[Any, Any, Any],
                               hooks_map: _C_H_MAP,
                               ) -> Tuple[Any, Any, Any]:
        # pylint: disable=no-self-use
        # pylint: disable=unused-argument
        pass # pragma: no cover

    def _execute_joining_hooks(self,
                               tokens: Sequence[str],
                               args: Union[Tuple[Sequence[Sequence[str]], Sequence[str], Sequence[Tuple[str, int]]],
                                           Tuple[Any, Any, Any]],
                               hooks_map: Union[_E_H_MAP, _C_H_MAP]
                               ) -> Union[Tuple[Sequence[Sequence[str]], Sequence[str], Sequence[Tuple[str, int]]],
                                          Tuple[Any, Any, Any]]:
        # pylint: disable=no-self-use
        key = tuple(tokens) if tuple(tokens) in hooks_map else 'DEFAULT'
        if key in hooks_map:
            args = reduce(lambda args, hook: hook(*args), hooks_map[key], args)
        return args

    def _compute_handled_groups(self,
                                groups: Sequence[Tuple[str, int]],
                                handled_tokens: Sequence[str],
                                ) -> Sequence[str]:
        start_index = 0
        handled_groups = []
        for group in groups:
            group_name, end_index = group
            group_handler = self._get_group_handler(group_name)
            handled_group = group_handler(group_name, handled_tokens[start_index: start_index + end_index])
            handled_groups.append(handled_group)
            start_index += end_index
        return tuple(handled_groups)

    def _get_group_handler(self, group_name: str) -> Callable[[str, Sequence[str]], str]:
        default_group_handler = lambda group_name, handled_tokens: '{{{}({})}}'.format(group_name,
                                                                                       ' '.join(handled_tokens))
        if self.group_handler_map:
            return (self.group_handler_map.get(group_name) or
                    self.group_handler_map.get('DEFAULT') or
                    default_group_handler)
        return default_group_handler

    def _expand_map_with_utterance_pattern_as_key(self,
                                                  map_with_utterance_pattern_as_key: _T_UP_KEY,
                                                  groups_map: Mapping[str, Sequence[str]]
                                                  ) -> _T_UP_KEY:
        # pylint: disable=no-self-use
        expanded_map = {}
        for key, hooks in map_with_utterance_pattern_as_key.items():
            if isinstance(key, str):
                expanded_map[key] = hooks
            else:
                expanded_utterance_patterns, _ = expand_utterance_patterns_ranges_and_groups((key,), groups_map)
                for expanded_utterance_pattern in expanded_utterance_patterns:
                    expanded_map[tuple(expanded_utterance_pattern)] = hooks # type: ignore
        return expanded_map

    def _validate_key_types_for_maps_with_utterance_pattern_as_key(self,
                                                                   maps: Iterable[Mapping]
                                                                   ) -> None:
        # Manually validating mappings as mypy does not support Mapping[Union[str, Tuple[str, ...]], Any]
        # https://github.com/python/mypy/issues/2300
        # Additionally TypedDict is not a good solution because we want to support arbitrary keys
        # pylint: disable=no-self-use, too-many-nested-blocks
        for map_with_utterance_patterns_as_key in maps:
            if map_with_utterance_patterns_as_key:
                for key in map_with_utterance_patterns_as_key.keys():
                    if isinstance(key, tuple):
                        for item in key:
                            if not isinstance(item, str):
                                raise ValueError("Each item in key: {}. Must be of type str.".format(key))
                    elif not isinstance(key, str):
                        raise ValueError("Invalid key: {}. Must be of type str or Tuple[str, ...].".format(key))

def _load_pattern_def(pattern_def_path: Path) -> Mapping:
    with pattern_def_path.open(encoding='utf-8') as pattern_def_file:
        pattern_def = yaml.load(pattern_def_file, Loader=yaml.BaseLoader)
    return pattern_def
